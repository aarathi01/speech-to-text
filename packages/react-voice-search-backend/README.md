# ðŸ§  Voice Search Backend (Node.js + Express + Vosk + MongoDB)

This is the backend server for the `react-voice-search-widget`, responsible for handling audio transcription and fuzzy database search. It uses the open-source Vosk speech recognition toolkit for offline transcription and MongoDB for storage.

---

## ðŸš€ Features

- ðŸŽ¤ Accepts audio input and converts it to text using Vosk.
- ðŸ” Performs fuzzy search on a MongoDB collection using keywords extracted from the input.
- ðŸ’¡ Returns highlighted matches to the frontend.
- ðŸ§± Modular, plug-and-play backend suitable for integration with multiple applications.

---

## ðŸ“ Folder Structure

```
server/
â”œâ”€â”€ db.js                 # MongoDB connection and search logic
â”œâ”€â”€ highlightUtils.js    # Utility to extract words and highlight them
â”œâ”€â”€ index.js             # Main server file (Express, Vosk integration)
â”œâ”€â”€ models/              # Directory to place the downloaded Vosk model
â””â”€â”€ uploads/             # Temp directory for audio uploads
```

---

## ðŸ§° Technologies Used

- **Node.js + Express** â€“ Backend framework
- **Vosk** â€“ Offline speech recognition engine
- **MongoDB** â€“ Data store
- **ffmpeg/fluent-ffmpeg** â€“ Audio processing
- **Multer** â€“ File uploads
- **CORS & Dotenv** â€“ Cross-origin and environment config

---

## ðŸ“¦ Setup Instructions

### 1. Clone the repo

```bash
git clone https://github.com/aarathi01/speech-to-text.git
cd speech-to-text/server
```

### 2. Install dependencies

```bash
npm install
```

### 3. Download Vosk Model

Download a Vosk model (e.g. `vosk-model-small-en-in-0.4`) from:

ðŸ”— https://alphacephei.com/vosk/models

Then, unzip and place it inside the `models/vosk` directory:

```
models/
â””â”€â”€ vosk/
    â”œâ”€â”€ am
    â”œâ”€â”€ conf
    â””â”€â”€ ...etc
```

### 4. Configure environment

Create a `.env` file in the `server` directory or use the existing `dev.env`:

```bash
MONGODB_URI=mongodb://[specified user name: specified password@]host 1[:specified port number 1][,â€¦.. host N][:specified port number N] 
PORT=5000
```

> You can also use separate env files per environment like `dev.env`, `prod.env`, etc.

### 5. Start the server

```bash
node index.js
```

The server should be running at:

```
http://localhost:5000
```

---

## ðŸ›  API Endpoints

### POST `/api/transcribe`

Accepts an audio file and returns the transcribed text.

**Request:**

- `multipart/form-data`
- field: `audio` (file: .wav)

**Response:**

```json
{ "text": "your transcribed text here" }
```

---

### GET `/search?q=...`

Performs a fuzzy search in the database using the provided query.

**Query Params:**

- `q`: (string) the input text or transcript

**Response:**

```json
{
  "results": [
    {
      "id": "...",
      "name": "...highlighted...",
      "category": "...highlighted...",
      "matchedWords": [...]
    }
  ]
}
```

---

## ðŸ§ª Testing

1. Use the `react-voice-search-widget` frontend to type or record input.
2. Confirm results appear automatically or with highlights.
3. Check the server console/logs for transcription and query debug info.

---

## ðŸ“‹ License

MIT Â© [aarathi01](https://github.com/aarathi01)